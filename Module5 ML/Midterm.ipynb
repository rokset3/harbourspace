{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Midterm test and practice session\n",
    "1. Questions.\n",
    "Please, answer the following questions briefly. Two or three sentences with main idea would be enough.\n",
    "\n",
    "Do not use external resourses in this part, please. Answer with you own words. If you forgot something, don't worry, we will discuss it later.\n",
    "\n",
    "1.0.\n",
    "### Please, formulate the supervised learning problem statement.\n",
    "\n",
    "##### Answer: \n",
    "The supervised learning problem is a problem where we have data and target. It is called supervised, as we have a human (usually), who supervises the data, and labels the target. It can be either classification or regression problem. So simply telling, supervised machine learning, is a machine learning problem where we have features and target columns, and we are trying to develop model which will map features into targets. As a classical example, is modeling titanic survival rate, given features of a person, we would like to estimate what is thet probability of him surviving titanic disaster. Or we could predict the price of the house given its features(num_rooms, location etc.)\n",
    "\n",
    "1.1.\n",
    "###  What are regression and classification problems. Whatâ€™s the difference?\n",
    "\n",
    "Regression and Classification problems are both supervised machine learning problems. In regression our target column is a real, continuous data. In classification we have categorical data. Example of regression can be predicting price of the house, which may vary and is continuous and here target $ \\in \\mathbb{R}^+$. For classification we could have a cat detection model, which target variable would be 0(non cat) and 1 (cat), and target $\\in {0,1}$. There are other more complex examples, but in simple words that is the description of the problem\n",
    "\n",
    "1.2.\n",
    "### Write down the linear model for regression problem in matrix notation. What is Mean Squared Error (MSE) loss function? How can it be expressed?\n",
    "\n",
    "Suppose we have a regression problem. We could construct a mathematical model $y = w\\times X + \\epsilon$, where $\\epsilon $ is a random vector, $y$ is the target variable, $w$ is the weights matrix and $X$ is the features matrix. Under following assumptions:\n",
    "$$\n",
    "\\mathop{\\mathbb{E}}(\\epsilon_i) = 0, \\forall i\\\\\n",
    "Var(\\epsilon_i) =  \\sigma^2 <inf, \\forall i \\\\\n",
    "Cov(\\epsilon_i, \\epsilon_j) = 0, \\forall i \\neq j\n",
    "$$\n",
    "We could find a respective weights $w$, such that they minimize Mean Squared Error of the model, which is defined by follows:\n",
    "$$\n",
    "\\mathcal{L}(w) = ||Y - w\\times X||^2_2 \n",
    "$$\n",
    "Here, $\\mathcal{L}(w)$ is a loss function of $w$, which measures the error of our model. Then we calculate loss for all predictions, and average it to get Mean Squared Loss. Finally, given all of the statements above, we cound find a Best Linear Estimator which would satisfy First Order Condition of a $\\mathcal{L}(w)$, and thus will minimize the loss using following formulae:\n",
    "$$\n",
    "w = (X^TX)^{-1}X^TY\n",
    "$$\n",
    "\n",
    "\n",
    "1.3.\n",
    "### What is the gradient of a function? How is it being used in optimization?\n",
    "\n",
    "In 1.2 I have shown the analytical solution for a linear regression problem. However, for a large datasets it may be computationally expensive to calculate $X^TX$, thus there is a optimization technique to solve this problem. The good point about MSE is that it is convex, continuous and differentiable. Thus we may find a derivative of it. Derivative is a rate of change by the way.\n",
    "Then, to minimize $\\mathcal{L}(w)$, we would use gradient descent algorithm, which can be simply described in the following equations below:\n",
    "$$\n",
    "w_t = w_{t-1} - \\alpha\\frac{d\\mathcal{L}(w_{t-1})}{dw_{t-1}}\n",
    "$$\n",
    "Here, $\\alpha$ is a learning rate, or rate by which we want to optimize our loss. $\\frac{d\\mathcal{L}(w)}{dw}$ is a derivative of a loss with the respect to weights. With this algorithm we would converge to a minima of a function.\n",
    "\n",
    "1.4.\n",
    "### Write down gradient descent step for linear model and MSE for one-dimensional case.\n",
    "\n",
    "$$\n",
    "w_t = w_{t-1} - \\alpha\\frac{d\\mathcal{L}(w_{t-1})}{dw_{t-1}}\n",
    "$$\n",
    "Here, $\\alpha$ is a learning rate, or rate by which we want to optimize our loss. $\\frac{d\\mathcal{L}(w)}{dw}$ is a derivative of a loss with the respect to weights. With this algorithm we would converge to a minima of a function.\n",
    "$$\n",
    " \\mathcal{L}(w) = (Y - w*X)^2 \\\\ \n",
    "\\frac{d\\mathcal{L}(w)}{dw} = 2X*(Y - w*X) \\\\\n",
    "$$\n",
    "Thus, the gradient algorithm will look like:\n",
    "$$\n",
    "w_t = w_{t-1} - 2\\alpha X(Y - w_{t-1}X)\n",
    "$$\n",
    "\n",
    "1.5.\n",
    "### What is validation? Cross validation?\n",
    "\n",
    "When we create a model, we want to evaluate its performance. Thus we split our data into train/val/test (train/test sometimes), so that we could fit our model with training data, and then measure its performance on the validation data. Cross validation is technique to measure the general performance of the model, since train/test/split can be affected by some randomness. Thus we split data into n batches, train our data on n-1 batches, and test in on the unseen last batch. We repeat this process by selecting another testing batch (for example n-2'st) and train on other batches, except for n-2. With this we would have n metrics and thus we would be able to evaluate model properly.  \n",
    "\n",
    "1.6.\n",
    "### What is regularization? How does L1 regularization differ from L2 for linear models?\n",
    "\n",
    "Regularization is a penalty term we add to the loss function. We need regularization to avoid overfitting and creating unstable solutions. There are a lot of types of regularization, and one of them are L1 and L2, which penalize model if its assigning very big weights $w$ for a model $h(w)$.\n",
    "For example, in MSE loss with linear regression L2 regularization would have the following expression:\n",
    "$$\n",
    "\\mathcal{L}(w) = ||Y - w\\times X||^2_2  + \\lambda||w||^2\n",
    "$$\n",
    "And L1 regularization would have the following expression:\n",
    "$$\n",
    "\\mathcal{L}(w) = ||Y - w\\times X||^2_2  + \\lambda||w||\n",
    "$$\n",
    "Here we can see, that we penalize model not only for high error, but for high weights too.\n",
    "The difference between L1 and L2 regularization, is the norm. In L1 we use Manhatten norm, in L2 we use Frobenious norm. For L1 regularization the shape of the function results in having sparse matrix of weights, allowing to perform feature selection, while L2 is smooth.\n",
    "\n",
    "\n",
    "1.7.\n",
    "### What are precision and recall metrics?\n",
    "\n",
    "Precision in simple words can be understood as a proprotion of correct predictions divided by total number of predictions, while Recall is a proportion of a correct predictions divded by the total number of ground truth labels. Precision is how precise we are, Recall is how many ground truth targets we found. The formulae is the following:\n",
    "$$\n",
    "Precision = \\frac{TP}{TP + FP}\\\\\n",
    "Recall = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "\n",
    "1.8.\n",
    "### What is bagging? What is the main idea beneath it?\n",
    "\n",
    "Bagging is a  Bootstrapp AGGregatING. This is an ensembling method, during which we train an ensemble of models on different subsets of the data created by Bootstrapping technique, and by averaging their predictions we would obtain final 'model' composed of different versions of the model. With bagging we may achieve better performance and generalization capability of the models.\n",
    "\n",
    "1.9.\n",
    "### How Random Forest is different from simple bagging?\n",
    "In Random forest we create subsets of data by random subspace method. Another difference, is that in Random Forest we may change the subset of features for each different tree, thus achieving more robust and different trees.\n",
    "\n",
    "1.10\n",
    "### What is gradient boosting? Is it a good idea to use linear regression as a basic model (element of the ensemble) in gradient boosting? What about logistic regression? Why?\n",
    "\n",
    "Gradient boosting is a technique by which we build ensemble of trees by trying to reduce the error of previous tree. In some different sources I found the notation of Gradient Boosting, is that it is an ensemble of weak learners, who learn specific part of the data. In GB we measure the loss of the prediction, and then we create a new tree which tries to learn the residual of the prediction, correcting the errors of previous one. The final, prediction is obtained by summing/weighted summing predictions from all of the weak simple trees.\n",
    "\n",
    "For linear regression it is useless sum of a linear models is a linear model itself. So we would not achieve much difference. For a logistic regression, however, since we have sigmoid activation, the gradient boosting can be good and help to learn complex, non-linear separable planes.\n",
    "\n",
    "2. Optional discussion\n",
    "### It is optional. We will contact you in private messages if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
