---
title: "Comparing classifiers"
output: html_document
---
For different versions of C4.5 algorithm we calculated AUC on 14 datasets: 
```{r echo=FALSE}
AUCS  <- matrix(c(0.763, 0.768, 0.771, 0.798,
                  0.599, 0.591, 0.590, 0.569,
                  0.954, 0.971, 0.968, 0.967,
                  0.628, 0.661, 0.654, 0.657,
                  0.882, 0.888, 0.886, 0.898,
                  0.936, 0.931, 0.916, 0.931,
                  0.661, 0.668, 0.609, 0.685,
                  0.583, 0.583, 0.563, 0.625,
                  0.775, 0.838, 0.866, 0.875,
                  1.000, 1.000, 1.000, 1.000,
                  0.940, 0.962, 0.965, 0.962,
                  0.619, 0.666, 0.614, 0.669,
                  0.972, 0.981, 0.975, 0.975,
                  0.957, 0.978, 0.946, 0.970), ncol=4, byrow = TRUE, 
                dimnames = list(c("adult (sample)", "breast cancer", "breast cancer wisconsin", "cmc", 
                                  "ionosphere", "iris", "liver disorders", "lung cancer", "lymphography", 
                                  "mushroom", "primary tumor", "rheum", "voting", "wine"),
                                c("C4.5", "C4.5+m", "C4.5+cf", "C4.5+m+cf")))

AUCS
```

Which versions are significantly different? 

Pairwise comparisons with signed rank test:
```{r warning=FALSE}
p <- data.frame(pair = c('1-2', '1-3', '1-4', '2-3', '2-4', '3-4'), 
                raw=rep(NA, 6))
p$raw[1] <- wilcox.test(AUCS[,1], AUCS[,2], paired=T, exact=T)$p.value
p$raw[2] <- wilcox.test(AUCS[,1], AUCS[,3], paired=T, exact=T)$p.value
p$raw[3] <- wilcox.test(AUCS[,1], AUCS[,4], paired=T, exact=T)$p.value
p$raw[4] <- wilcox.test(AUCS[,2], AUCS[,3], paired=T, exact=T)$p.value
p$raw[5] <- wilcox.test(AUCS[,2], AUCS[,4], paired=T, exact=T)$p.value
p$raw[6] <- wilcox.test(AUCS[,3], AUCS[,4], paired=T, exact=T)$p.value

library(formattable)
signif_bold <- formatter("span", style = x ~ style("font-weight" = ifelse(x <= 0.05, "bold", NA)))
formattable(p, list(raw = signif_bold))
```

Different multiple hypothesis testing adjustments:
```{r}
p$bonferroni <- p.adjust(p$raw, "bonferroni")
p$holm       <- p.adjust(p$raw, "holm")
p$BH         <- p.adjust(p$raw, "BH")
p$BY         <- p.adjust(p$raw, "BY")

formattable(p, list(raw = signif_bold, bonferroni = signif_bold, holm = signif_bold, BH = signif_bold, BY = signif_bold))
```

Another method that takes into account the correlation structure due to the fact that the same samples are being compared:
```{r}
library(PMCMRplus)
frdAllPairsNemenyiTest(AUCS)
```
**************
Demsar J. (2006). **Statistical Comparisons of Classifiers over Multiple Data Sets**. Journal of Machine Learning Research, 7, 1â€“30.
