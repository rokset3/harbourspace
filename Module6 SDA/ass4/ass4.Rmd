---
title: "assignment4"
author: "TemmirlanZholaman"
date: "2023-02-23"
output: html_document
---
```{r, echo=FALSE,  warning=FALSE, message=FALSE}

library(forecast)
library(tseries)
library(lmtest)
library(Hmisc)
library(lubridate)
setwd('C:\\Users\\Temirlan\\Desktop\\HarbourSpace\\Module6 SDA\\ass4')
data <- read.csv("Electric_Production.csv", sep=",", stringsAsFactors=F)
names(data)[1] <- "Date"
names(data)[2] <- "Value"
xname <- "Monthly electricity production"
data$Value <- as.numeric(data$Value)
data$Date <- as.Date(as.character(data$Date), format = "%m/%d/%Y")


tSeries <- ts(data = data$Value, start = as.numeric(c(format(data$Date[1], "%Y"), format(data$Date[1], "%m"))), freq = 12)

plot(tSeries, type="l", ylab=xname, col="red")
grid()

D<-39

trainSeries <- window(tSeries, end  =c(year(data$Date[length(data$Date)-D]),  month(data$Date[length(data$Date)-D])))
testSeries  <- window(tSeries, start=c(year(data$Date[length(data$Date)-D+1]),month(data$Date[length(data$Date)-D+1])))
```
I will keep the entire dataset.
```{r, echo=FALSE, fig.height=8, fig.width=10}
plot(stl(tSeries, s.window="periodic"))
```
Box-Cox transformation with optimal $\lambda$:
```{r, echo=FALSE, fig.width=10, fig.height=8}
par(mfrow=c(2,1))
plot(tSeries, ylab="Original series", xlab="", col="red")
grid()

LambdaOpt <- BoxCox.lambda(tSeries)
plot(BoxCox(tSeries, LambdaOpt), ylab="Transformed series", xlab="", col="red")
title(main=toString(round(LambdaOpt, 3)))
grid()
```

```{r, echo=FALSE}
fit.auto <- auto.arima(tSeries, lambda=LambdaOpt, biasadj=T)
fit.auto
```

ARIMA(1,1,1)(1,1,2)$_{12}$ is selected. Here are the residuals:
```{r, echo=FALSE, fig.height=4.5, fig.width=10}
res.auto <- residuals(fit.auto)
plot(res.auto)
```
At the beginning residuals are not defined properly; let's cut the first 12 before proceeding with residual analysis.
```{r, echo=FALSE, fig.height=8, fig.width=10}
res.auto <- res.auto[-c(1:12)]
tsdisplay(res.auto)
```
```{r, echo=FALSE}
p <- rep(0, 1, frequency(tSeries)*3)
for (i in 1:length(p)){
  p[i] <- Box.test(res.auto, lag=i, type = "Ljung-Box")$p.value
}
plot(p, xlab="Lag", ylab="p-values", ylim=c(0,1), main="Ljung-Box test")
abline(h = 0.05, lty = 2, col = "blue")
```
```{r, echo=FALSE, fig.height=5.5, fig.width=10}
par(mfrow=c(1,2))
qqnorm(res.auto)
qqline(res.auto, col="red")
hist(res.auto)
```

Hypothesis   | Test         | Result         | P-value
------------ | ------------ | -------------- | ------------------------------
Normality    | Shapiro-Wilk | not rejected   | `r shapiro.test(res.auto)$p.value`
Unbiasedness | Wilcoxon     | not rejected   | `r wilcox.test(res.auto)$p.value`
Stationarity | KPSS         | not rejected   | `r kpss.test(res.auto)$p.value`

Fitting the selected model to the first $T-D$ points of the series to check the accuracy of the forecast on the last $D$ points:
```{r, echo=FALSE}
fitShort <- Arima(trainSeries, order=c(1,1,1), seasonal=c(1,1,2), lambda=LambdaOpt, biasadj = T)
fc       <- forecast(fitShort, h=D)
accuracy(fc, testSeries)
```
```{r, echo=FALSE, fig.height=5.5, fig.width=10}
plot(forecast(fitShort, h=D), ylab=xname, xlab="Time")
lines(tSeries, col="red")
```


### Manual model tuning
The series is nonstationary (p<`r kpss.test(BoxCox(tSeries, LambdaOpt))$p.value`, KPSS test) and  seasonal; let's do seasonal differencing:
```{r, echo=FALSE, fig.height=5.5, fig.width=10}
plot(diff(BoxCox(tSeries, LambdaOpt), 12), type="l", col="red")
grid()
```
Still not stationary (p<`r kpss.test(diff(BoxCox(tSeries, LambdaOpt), 12))$p.value`, KPSS test. Let's do another, nonseasonal differencing:
```{r, echo=FALSE, fig.height=5.5, fig.width=10}
plot(diff(diff(BoxCox(tSeries, LambdaOpt), 12), 1), type="l", col="red")
grid()
```
The hypothesis of stationarity is now not rejected (p>`r kpss.test(diff(diff(BoxCox(tSeries, LambdaOpt), 12), 1))$p.value`, KPSS test).


```{r, echo=FALSE, fig.height=5.5, fig.width=12}
par(mfrow=c(1,2))
acf(diff(diff(BoxCox(tSeries, LambdaOpt), 12), 1), lag.max=5*12, main="")
pacf(diff(diff(BoxCox(tSeries, LambdaOpt), 12), 1), lag.max=5*12, main="")
```
Autocorrelation is significantly different from 0 for lags 1, 2, 3, 10, 11, 12, 24, 39 and 53 
Since 24 is maximal significant seasonal lag, we could use $Q = 24/12 = 2$ as an initial approximation.
Maximal significant lag before 12 is 11, hence the starting value $q=11$.

Partial autocorrelation is significantly different from 0 for lags 1, 2, 4, 5, 10, 11, 12, 13(debatable), 14, 23, 24, 34, 35 ,36, 48, 53, 58 
Following the same logic as above, we select initial values $P=4$, $p=11$.

Now I'll look for the best models with auto.arima using d=1, D=1, max.p=10, max.q=11, max.P=4, max.Q=4 (where possible, I added 1 to every initial approximation found above just in case), and the parameters of the automatic model as starting points of the search (start.p=2, start.q=1, start.P=2, start.Q=1). 
```{r echo=F}
fit <- auto.arima(tSeries, d=1, D=1, max.p=10, max.q=11, max.P = 4, max.Q = 4, 
                  start.p=2, start.q=1, start.P=2, start.Q=1, 
                  lambda=LambdaOpt, biasadj=T)
fit
```
The lowest AICc has ARIMA(2,1,1)(0,1,1)$_{12}$. Does it have good residuals?
```{r, echo=FALSE, fig.height=4.5, fig.width=10}
res <- residuals(fit)
plot(res)
```
Residuals are OK I think, lets explore without first 12 months

```{r, echo=FALSE, fig.height=8, fig.width=10}
res <- res[-c(1:12)]
tsdisplay(res)
```
```{r, echo=FALSE}
p <- rep(0, 1, frequency(tSeries)*3)
for (i in 1:length(p)){
  p[i] <- Box.test(res, lag=i, type = "Ljung-Box")$p.value
}
plot(p, xlab="Lag", ylab="p-values", ylim=c(0,1), main="Ljung-Box test")
abline(h = 0.05, lty = 2, col = "blue")
```
Q-Q plot and histogram of the residuals:
```{r, echo=FALSE, fig.height=5.5, fig.width=10}
par(mfrow=c(1,2))
qqnorm(res)
qqline(res, col="red")
hist(res)
```

Hypothesis   | Test         | Result         | P-value
------------ | ------------ | -------------- | ------------------------------
Normality    | Shapiro-Wilk | not rejected   | `r shapiro.test(res)$p.value`
Unbiasedness | Wilcoxon     | not rejected   | `r wilcox.test(res)$p.value`
Stationarity | KPSS         | not rejected   | `r kpss.test(res)$p.value`

Fitting the selected model to the first $T-D$ points of the series to check the accuracy of the forecast on the last $D$ points:
```{r, echo=FALSE, fig.height=5.5, fig.width=10}
fitShort <- Arima(trainSeries, order=c(2,1,1), seasonal=c(0,1,1), lambda=LambdaOpt, biasadj = T)
fc       <- forecast(fitShort, h=D)
accuracy(fc, testSeries)
```
```{r, echo=FALSE, fig.height=5.5, fig.width=10}
plot(forecast(fitShort, h=D), ylab=xname, xlab="Year")
lines(tSeries, col="red")
```

### ETS model
```{r, echo=FALSE}
fit.ets <- ets(tSeries, lambda=LambdaOpt, biasadj = T)
print(fit.ets)
```
Residuals:
```{r, echo=FALSE, fig.height=8, fig.width=10}
tsdisplay(residuals(fit.ets))
```
Ljung-Box test p-values for them:

```{r, echo=FALSE}
p <- rep(0, 1, frequency(tSeries)*3)
for (i in 1:length(p)){
  p[i] <- Box.test(residuals(fit.ets), lag=i, type = "Ljung-Box")$p.value
}
plot(p, xlab="Lag", ylab="p-values", ylim=c(0,1), main="Ljung-Box test")
abline(h = 0.05, lty = 2, col = "blue")
```
The residuals are correlated, the model does not take into account all the structure in the data.

```{r, echo=FALSE, fig.height=5.5, fig.width=10}
par(mfrow=c(1,2))
qqnorm(residuals(fit.ets))
qqline(residuals(fit.ets), col="red")
hist(residuals(fit.ets))
```

Hypothesis   | Test         | Result         | P-value
------------ | ------------ | -------------- | ------------------------------
Normality    | Shapiro-Wilk | not rejected   | `r shapiro.test(residuals(fit.ets))$p.value`
Unbiasedness | Wilcoxon     | not rejected   | `r wilcox.test(residuals(fit.ets))$p.value`
Stationarity | KPSS         | not rejected   | `r kpss.test(residuals(fit.ets))$p.value`

Fitting the selected model to the first $T-D$ points of the series to check the accuracy of the forecast on the last $D$ points:
```{r, echo=FALSE}
fitShort <- ets(trainSeries, model="AAA", damped=F, lambda=LambdaOpt, biasadj = T)
fc       <- forecast(fitShort, h=D)
accuracy(fc, testSeries)
```
```{r, echo=FALSE, fig.height=5.5, fig.width=10}
plot(forecast(fitShort, h=D), ylab=xname, xlab="Year")
lines(tSeries, col="red")
```

## Final model selection

Comparing the residuals of two ARIMAs:
```{r, echo=FALSE, fig.height=8, fig.width=8}
res      <- residuals(fit, type = "response")[-c(1:12)]
res.auto <- residuals(fit.auto, type = "response")[-c(1:12)]

plot(res, res.auto, xlim=c(min(res, res.auto), max(res, res.auto)), ylim=c(min(res, res.auto), max(res, res.auto)), 
     xlab = "Residuals of manually found model", ylab="Residuals of auto.arima model")
grid()
lines(c(min(res, res.auto), max(res, res.auto))*2, c(min(res, res.auto), max(res, res.auto))*2, col="red")
```
```{r, echo=F}
dm.test(res, res.auto)
```
Diebold-Mariano test does not find the differences between forecasting errors of two ARIMAs significant. 
The residuals of two models have the same properties. 
While their AICc score is nearly the same, manually tuned ARIMA shows smaller losses on test set and lower Theil's U, so we stick with it.

Now let's compare it to ets model
Comparing the residuals of the best ARIMA and the best ETS models:
```{r fig.width=8, fig.height=8, echo=FALSE}
res.ets <- residuals(fit.ets, type = "response")[-c(1:12)]

plot(res, res.ets, 
     xlab="Residuals, best ARIMA",
     ylab="Residuals, best ETS",
     xlim=c(min(c(res, res.ets), na.rm=T), max(c(res, res.ets), na.rm=T)),
     ylim=c(min(c(res, res.ets), na.rm=T), max(c(res, res.ets), na.rm=T)))
 lines(c(min(c(res, res.ets), na.rm=T), max(c(res, res.ets), na.rm=T)), c(min(c(res, res.ets), na.rm=T), max(c(res, res.ets), na.rm=T)), col="red")
```
```{r, echo=F}
dm.test(res, res.ets)
dm.test(res, res.ets, alternative = "less")
```
Diebold-Mariano Test cannot say whether ARIMA is better than ETS model. 
ETS model had good training losses, but worse test losses. Also its Theul's U is much bigger than ARIMA's one, and its residuals are auto correlated, so I want to stick to ARIMA model more.
Finally, by observing predictions on the test set, it can be observed, that ETS model overpredicts most of the times, while ARIMA's predictions look better in general. So I will make a forecast with manually tuned ARIMA.

## Forecast
```{r, echo=FALSE}
fl <- forecast(fit, h=D)
print(fl)

```
```{r, echo=FALSE, fig.height=5.5, fig.width=10}
plot(fl, ylab=xname, xlab="Year", col="red")
```